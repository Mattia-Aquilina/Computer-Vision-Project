{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['CompVis_stable-diffusion-v1-4', 'DeepFloyd_IF-II-L-v1.0', 'Real', 'stabilityai_stable-diffusion-2-1-base', 'stabilityai_stable-diffusion-xl-base-1.0']\n",
    "NUM_OF_CLASSES = len(LABELS)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "#Adjust the paths as needed\n",
    "BASE_PATH = '/content/drive/MyDrive/Computer-Vision'\n",
    "DATASET_PATH = BASE_PATH + '/Dataset/'\n",
    "MODEL_PATH = BASE_PATH + '/Models/FineTuning/model-8-Epochs.h5'\n",
    "CSV_FILES_PATHS = [BASE_PATH + '/ChartData/Results-V1-FineTuning-Batch64.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Loss charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script will assume to parse CSV files with the following columns:\n",
    "# - N.EPOCHS\n",
    "# - ACCURACY (training accuracy)\n",
    "# - LOSS (training loss)\n",
    "# - VAL_ACCURACY (validation accuracy)\n",
    "# - VAL_LOSS (validation loss)\n",
    "\n",
    "for file_path in CSV_FILES_PATHS:\n",
    "  model_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "  if (model_name.startswith(\"Results-\")):\n",
    "    model_name = model_name.removeprefix(\"Results-\")\n",
    "\n",
    "  data = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "  data['ACCURACY'] = data['ACCURACY'] * 100\n",
    "  data['VAL_ACCURACY'] = data['VAL_ACCURACY'] * 100\n",
    "\n",
    "  plt.subplots(1,2, figsize=(15,5))\n",
    "  plt.subplot(121)\n",
    "\n",
    "  plt.plot(data['N.EPOCHS'], data['ACCURACY'], 'b', linewidth=1.5, label='Training', marker=\"o\", markersize=5)\n",
    "  plt.plot(data['N.EPOCHS'], data['VAL_ACCURACY'], 'r', linewidth=1.5, label='Validation', marker=\"o\", markersize=5)\n",
    "\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy (%)')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.title(\"Model Accuracy\")\n",
    "\n",
    "  plt.subplot(122)\n",
    "\n",
    "  plt.plot(data['N.EPOCHS'], data['LOSS'], 'b', linewidth=1.5, label='Training', marker=\"o\", markersize=5)\n",
    "  plt.plot(data['N.EPOCHS'], data['VAL_LOSS'], 'r', linewidth=1.5, label='Validation', marker=\"o\", markersize=5)\n",
    "\n",
    "  loss_min = data[['LOSS', 'VAL_LOSS']].min().min()\n",
    "  loss_max = data[['LOSS', 'VAL_LOSS']].max().max()\n",
    "  loss_ticks = np.linspace(loss_min, loss_max, num=10)\n",
    "  plt.yticks(loss_ticks)\n",
    "\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title(\"Model loss\")\n",
    "\n",
    "  plt.suptitle(model_name, fontsize=15)\n",
    "\n",
    "  plt.show()\n",
    "  plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(image , label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "\n",
    "builder = tfds.folder_dataset.ImageFolder(DATASET_PATH)\n",
    "raw_test = builder.as_dataset(split='test', as_supervised=True)\n",
    "\n",
    "info = builder.info\n",
    "\n",
    "print(\"Total test images: {}  \".format(len(raw_test)) )\n",
    "print(\"Label names: {}\".format(info.features['label'].names))\n",
    "\n",
    "test = raw_test.map(format_image)\n",
    "\n",
    "test_batches = test.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array([], dtype='int16')\n",
    "predicted_labels = np.array([], dtype='int16')\n",
    "rejection_threshold = 0.3\n",
    "\n",
    "for image_batch, label_batch in tqdm(test_batches, total=len(test_batches), desc=\"Predicting: \"):\n",
    "  for i in range(len(image_batch)):\n",
    "    image = np.expand_dims(image_batch[i], axis=0)\n",
    "    true_label = label_batch[i]\n",
    "\n",
    "    prediction = model.predict(image)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "    prediction_prob = prediction[0][predicted_class] * 100\n",
    "\n",
    "    if (prediction_prob < rejection_threshold * 100):\n",
    "      predicted_class = np.array([5])\n",
    "\n",
    "    true_labels = np.concatenate((true_labels, [true_label.numpy()]))\n",
    "    predicted_labels = np.concatenate((predicted_labels, predicted_class))\n",
    "\n",
    "unknown_count = np.sum(predicted_labels == 5)\n",
    "total_predictions = len(predicted_labels)\n",
    "unknown_percentage = (unknown_count / total_predictions) * 100\n",
    "\n",
    "print(unknown_count)\n",
    "print(total_predictions)\n",
    "print(unknown_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_labels.flatten(), predicted_labels.flatten())\n",
    "conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(conf_matrix_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar(shrink=0.7)\n",
    "\n",
    "tick_marks = np.arange(NUM_OF_CLASSES)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "\n",
    "thresh = conf_matrix_norm.max() / 2.\n",
    "\n",
    "for i, j in itertools.product(range(conf_matrix_norm.shape[0]), range(conf_matrix_norm.shape[1])):\n",
    "    plt.text(j, i, format(conf_matrix_norm[i, j], '.2f'),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if conf_matrix_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
