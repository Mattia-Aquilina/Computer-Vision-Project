{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30156,"status":"ok","timestamp":1721027684022,"user":{"displayName":"mattia aquilina","userId":"11732568340087897820"},"user_tz":-120},"id":"gRMVl2I_OPX5","outputId":"598dbcf6-de48-4489-ee8e-a9dfa1c2d2d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","import os\n","\n","from tqdm import tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","IMG_SIZE = 224\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","\n","BATCH_SIZE= 128\n","SHUFFLE_BUFFER_SIZE= 1000\n","\n","initial_epochs = 5"]},{"cell_type":"markdown","metadata":{"id":"piBy3_mp5MEg"},"source":[]},{"cell_type":"code","source":["train_dir = '/content/drive/MyDrive/Computer-Vision/Dataset/train'\n","validation_dir = '/content/drive/MyDrive/Computer-Vision/Dataset/val'"],"metadata":{"id":"Ar_BrsoGMd4t","executionInfo":{"status":"ok","timestamp":1721027684022,"user_tz":-120,"elapsed":4,"user":{"displayName":"mattia aquilina","userId":"11732568340087897820"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**DATA AUGMENTATION**\n"],"metadata":{"id":"wzBg3GjyLcHs"}},{"cell_type":"code","source":["datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.3,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    zoom_range = 0.3,\n","    data_format='channels_last',\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",")\n","\n","train_generator = datagen.flow_from_directory(\n","    train_dir,\n","    target_size= (IMG_SIZE, IMG_SIZE),\n","    color_mode='rgb',\n","    shuffle=True,\n","    class_mode='categorical',\n","    batch_size=BATCH_SIZE\n",")\n","\n","val_generator= datagen.flow_from_directory(\n","    validation_dir,\n","    target_size= (IMG_SIZE,IMG_SIZE),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=BATCH_SIZE\n",")"],"metadata":{"id":"18vB-XzVLUys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721027729384,"user_tz":-120,"elapsed":45364,"user":{"displayName":"mattia aquilina","userId":"11732568340087897820"}},"outputId":"108cde2e-8f77-4e97-9c04-1082c9ca1cca"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 36800 images belonging to 5 classes.\n","Found 4592 images belonging to 5 classes.\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RS08U8MNjhvG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721027731479,"user_tz":-120,"elapsed":2098,"user":{"displayName":"mattia aquilina","userId":"11732568340087897820"}},"outputId":"6b8e88ef-827a-4958-c2fd-c23834ce5044"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9406464/9406464 [==============================] - 0s 0us/step\n"]}],"source":["#Model for fine-tuning\n","base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', input_shape=IMG_SHAPE)\n","\n","num_layers_to_unfreeze = 8\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","for layer in base_model.layers[-num_layers_to_unfreeze:]:\n","    layer.trainable = True\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6cHbS31UOhjy","executionInfo":{"status":"ok","timestamp":1721027731887,"user_tz":-120,"elapsed":411,"user":{"displayName":"mattia aquilina","userId":"11732568340087897820"}}},"outputs":[],"source":["\n","average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","#first_dense_layer = tf.keras.layers.Dense(units=128, activation='relu')\n","#second_dense_layer = tf.keras.layers.Dense(units=64, activation='relu')\n","prediction_layer = tf.keras.layers.Dense(units=5, activation='softmax')\n","\n","new_model = tf.keras.Sequential([\n","    base_model,\n","    average_layer,\n","    #first_dense_layer,\n","    #second_dense_layer,\n","    prediction_layer\n","])\n","\n","\n","new_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1720893338264,"user":{"displayName":"mattia aquilina","userId":"11732568340087897820"},"user_tz":-120},"id":"9haMEzwRI7zn","outputId":"ca8f438b-cb72-4edf-9279-11ea8bd0e4e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n"," tional)                                                         \n","                                                                 \n"," global_average_pooling2d_1  (None, 1280)              0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n"," dense_3 (Dense)             (None, 5)                 6405      \n","                                                                 \n","=================================================================\n","Total params: 2264389 (8.64 MB)\n","Trainable params: 736965 (2.81 MB)\n","Non-trainable params: 1527424 (5.83 MB)\n","_________________________________________________________________\n"]}],"source":["new_model.summary()"]},{"cell_type":"markdown","source":["**Load the model in case of checkpoints**"],"metadata":{"id":"chA4P3qIOwU9"}},{"cell_type":"code","source":["new_model = tf.keras.models.load_model('/content/drive/MyDrive/Computer-Vision/Models/FineTuning/8-conv-unlocked/model-16e.h5')"],"metadata":{"id":"LGBxosuCmEJv","executionInfo":{"status":"ok","timestamp":1721055469774,"user_tz":-120,"elapsed":5253,"user":{"displayName":"mattia aquilina","userId":"11732568340087897820"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYH0tPgNsOau","outputId":"fe2ce5c1-c1d1-4dc5-d113-e007c66d55ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","288/288 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.8139 \n","Epoch 1: saving model to /content/drive/MyDrive/Computer-Vision/Models/FineTuning/8-conv-unlocked/model-21e.h5\n","288/288 [==============================] - 3372s 12s/step - loss: 0.4378 - accuracy: 0.8139 - val_loss: 0.9935 - val_accuracy: 0.7012\n","Epoch 2/5\n","288/288 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8172 \n","Epoch 2: saving model to /content/drive/MyDrive/Computer-Vision/Models/FineTuning/8-conv-unlocked/model-21e.h5\n","288/288 [==============================] - 3392s 12s/step - loss: 0.4278 - accuracy: 0.8172 - val_loss: 0.8726 - val_accuracy: 0.7125\n","Epoch 3/5\n","288/288 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.8218 \n","Epoch 3: saving model to /content/drive/MyDrive/Computer-Vision/Models/FineTuning/8-conv-unlocked/model-21e.h5\n","288/288 [==============================] - 3422s 12s/step - loss: 0.4134 - accuracy: 0.8218 - val_loss: 0.8306 - val_accuracy: 0.7156\n","Epoch 4/5\n","259/288 [=========================>....] - ETA: 5:07 - loss: 0.4098 - accuracy: 0.8237"]}],"source":["#Training for fine-tuning\n","early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","check_point_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='/content/drive/MyDrive/Computer-Vision/Models/FineTuning/8-conv-unlocked/model-21e.h5',\n","    monitor='val_loss',\n","    save_best_only=False,\n","    save_weights_only=False,\n","    mode='min',\n","    verbose=1\n",")\n","\n","history = new_model.fit(train_generator, epochs=5, validation_data=val_generator, verbose=1, callbacks=[early_stop_callback, check_point_callback])\n","acc = history.history['accuracy']\n","print(acc)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1foNmIV7jViDNp9T9K_xznvPhHxlcf6nz","timestamp":1720892992471}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}